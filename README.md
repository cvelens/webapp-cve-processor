# CVELens Processor Web Application

## Overview

The CVELens Processor Web Application is a Go application designed to download, process, and publish Common Vulnerabilities and Exposures (CVE) data to a Kafka topic. It's a critical component in a larger system for managing and analyzing CVE information.

## Features

- Downloads the latest CVE data from the official source
- Processes JSON files containing CVE information
- Publishes processed CVE records to a Kafka topic
- Implements health checks for liveness and readiness probes
- Designed for deployment in a Kubernetes environment

## Prerequisites

- Go 1.x (version used in the project)
- Docker
- Access to a Kafka cluster
- Kubernetes cluster (for deployment)

## Configuration

The application is configured using environment variables:

- `KAFKA_BROKERS`: Comma-separated list of Kafka broker addresses
- `KAFKA_TOPIC`: Kafka topic to publish CVE data to

## Local Development

1. Clone the repository:
   ```
   git clone https://github.com/cvelens/webapp-cve-processor.git
   cd webapp-cve-processor
   ```

2. Install dependencies:
   ```
   go mod download
   ```

3. Set up environment variables (use a `.env` file or export them)

4. Run the application:
   ```
   go run main.go
   ```

## Building the Docker Image

To build the Docker image locally:

```
docker build -t webapp-cve-processor:latest .
```

## Deployment

The application is designed to be deployed in a Kubernetes environment. Refer to the Helm chart in the `helm-webapp-cve-processor` repository for deployment configurations.

## Health Checks

- Liveness Probe: `/usr/local/bin/liveness-check.sh`
- Readiness Probe: `/usr/local/bin/readiness-check.sh`

These scripts check the application's health and its ability to connect to Kafka.

## Data Processing

The processor performs the following steps:
1. Downloads the latest CVE data ZIP file
2. Extracts and processes JSON files from the ZIP
3. Parses each CVE record
4. Publishes the processed records to the specified Kafka topic

## CI/CD Pipeline
This repository follows a CI/CD process that integrates GitHub and Jenkins using webhooks to trigger automated workflows. The CI/CD process ensures that code quality, chart validation, and versioning are handled automatically before code can be merged and released.

### CI/CD Workflow Overview
#### GitHub -> Jenkins Integration
- GitHub Webhook: A webhook is configured on this repository to trigger Jenkins jobs on specific GitHub events (e.g., pull requests).
- Jenkins Pipelines: There are two Jenkins pipelines (Jenkinsfile1 and Jenkinsfile2) that handle validation, building, tagging, and publishing multi-architecture Docker images supporting ARM64 and AMD64 platforms.

#### CI/CD Pipeline Flow
##### Code Validation and Linting (Jenkinsfile1)

- Trigger: Pull requests to the main branch
- This pipeline performs several checks to ensure that the commit messages adhere to the Conventional Commits standard before allowing a merge.

##### Helm Chart Publishing (Jenkinsfile2)
- Trigger: Merging a pull request into the main branch
- Once the code passes all validations, and a pull request is merged, this pipeline automatically versions, tags and publishes the Docker image to DockerHub Registry.

## Version Management

The project uses semantic versioning. The `get_next_version.sh` script is used to determine the next version based on commit messages.
