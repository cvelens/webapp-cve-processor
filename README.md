```markdown
# webapp-cve-processor

## Overview

The webapp-cve-processor is a Go application designed to download, process, and publish Common Vulnerabilities and Exposures (CVE) data to a Kafka topic. It's a critical component in a larger system for managing and analyzing CVE information.

## Features

- Downloads the latest CVE data from the official source
- Processes JSON files containing CVE information
- Publishes processed CVE records to a Kafka topic
- Implements health checks for liveness and readiness probes
- Designed for deployment in a Kubernetes environment

## Prerequisites

- Go 1.x (version used in the project)
- Docker
- Access to a Kafka cluster
- Kubernetes cluster (for deployment)

## Configuration

The application is configured using environment variables:

- `KAFKA_BROKERS`: Comma-separated list of Kafka broker addresses
- `KAFKA_TOPIC`: Kafka topic to publish CVE data to

## Local Development

1. Clone the repository:
   ```
   git clone https://github.com/your-org/webapp-cve-processor.git
   cd webapp-cve-processor
   ```

2. Install dependencies:
   ```
   go mod download
   ```

3. Set up environment variables (use a `.env` file or export them)

4. Run the application:
   ```
   go run main.go
   ```

## Building the Docker Image

To build the Docker image locally:

```
docker build -t webapp-cve-processor:latest .
```

## Deployment

The application is designed to be deployed in a Kubernetes environment. Refer to the Helm chart in the `helm-webapp-cve-processor` repository for deployment configurations.

## Health Checks

- Liveness Probe: `/usr/local/bin/liveness-check.sh`
- Readiness Probe: `/usr/local/bin/readiness-check.sh`

These scripts check the application's health and its ability to connect to Kafka.

## Data Processing

The processor performs the following steps:
1. Downloads the latest CVE data ZIP file
2. Extracts and processes JSON files from the ZIP
3. Parses each CVE record
4. Publishes the processed records to the specified Kafka topic

## CI/CD

The repository includes Jenkins pipeline configurations:

- `Jenkinsfile`: For pull request checks (conventional commits, etc.)
- `Jenkinsfile2`: For building and pushing Docker images on the main branch

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Please ensure your commit messages follow the conventional commits specification.

## Version Management

The project uses semantic versioning. The `get_next_version.sh` script is used to determine the next version based on commit messages.
