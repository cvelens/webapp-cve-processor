package main

import (
	"archive/zip"
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"io/ioutil"
	"log"
	"net/http"
	"os"
	"strings"
	"time"

	"github.com/IBM/sarama"
)

type CVERecord struct {
	Containers struct {
		CNA struct {
			Affected []struct {
				Product  string `json:"product"`
				Vendor   string `json:"vendor"`
				Versions []struct {
					Status  string `json:"status"`
					Version string `json:"version"`
				} `json:"versions"`
			} `json:"affected"`
			Descriptions []struct {
				Lang  string `json:"lang"`
				Value string `json:"value"`
			} `json:"descriptions"`
			ProblemTypes []struct {
				Descriptions []struct {
					Description string `json:"description"`
					Lang        string `json:"lang"`
					Type        string `json:"type"`
				} `json:"descriptions"`
			} `json:"problemTypes"`
			ProviderMetadata struct {
				DateUpdated string `json:"dateUpdated"`
				OrgID       string `json:"orgId"`
				ShortName   string `json:"shortName"`
			} `json:"providerMetadata"`
			References []struct {
				Name string   `json:"name"`
				Tags []string `json:"tags"`
				URL  string   `json:"url"`
			} `json:"references"`
			XLegacyV4Record struct {
				CVEDataMeta struct {
					Assigner string `json:"ASSIGNER"`
					ID       string `json:"ID"`
					State    string `json:"STATE"`
				} `json:"CVE_data_meta"`
				Affects struct {
					Vendor struct {
						VendorData []struct {
							Product struct {
								ProductData []struct {
									ProductName string `json:"product_name"`
									Version     struct {
										VersionData []struct {
											VersionValue string `json:"version_value"`
										} `json:"version_data"`
									} `json:"version"`
								} `json:"product_data"`
							} `json:"product"`
							VendorName string `json:"vendor_name"`
						} `json:"vendor_data"`
					} `json:"vendor"`
				} `json:"affects"`
				DataFormat  string `json:"data_format"`
				DataType    string `json:"data_type"`
				DataVersion string `json:"data_version"`
				Description struct {
					DescriptionData []struct {
						Lang  string `json:"lang"`
						Value string `json:"value"`
					} `json:"description_data"`
				} `json:"description"`
				ProblemType struct {
					ProblemTypeData []struct {
						Description []struct {
							Lang  string `json:"lang"`
							Value string `json:"value"`
						} `json:"description"`
					} `json:"problemtype_data"`
				} `json:"problemtype"`
				References struct {
					ReferenceData []struct {
						Name      string `json:"name"`
						Refsource string `json:"refsource"`
						URL       string `json:"url"`
					} `json:"reference_data"`
				} `json:"references"`
			} `json:"x_legacyV4Record"`
		} `json:"cna"`
	} `json:"containers"`
	CveMetadata struct {
		AssignerOrgID     string `json:"assignerOrgId"`
		AssignerShortName string `json:"assignerShortName"`
		CveID             string `json:"cveId"`
		DatePublished     string `json:"datePublished"`
		DateReserved      string `json:"dateReserved"`
		DateUpdated       string `json:"dateUpdated"`
		State             string `json:"state"`
	} `json:"cveMetadata"`
	DataType    string `json:"dataType"`
	DataVersion string `json:"dataVersion"`
}

func main() {
	brokerString := os.Getenv("KAFKA_BROKERS")
	if brokerString == "" {
		log.Fatal("KAFKA_BROKERS environment variable is not set")
	}
	brokers := strings.Split(brokerString, ",")

	topic := os.Getenv("KAFKA_TOPIC")
	if topic == "" {
		log.Fatal("KAFKA_TOPIC environment variable is not set")
	}

	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5
	config.Producer.Retry.Backoff = time.Second * 2
	config.Net.DialTimeout = time.Second * 10
	config.Net.ReadTimeout = time.Second * 10
	config.Net.WriteTimeout = time.Second * 10
	config.Metadata.Retry.Max = 5
	config.Metadata.Retry.Backoff = time.Second * 2
	config.Producer.Return.Successes = true
	config.Version = sarama.V2_8_0_0 // Use the version that matches your Kafka server

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		log.Fatalf("Error creating Kafka producer: %v", err)
	}
	defer producer.Close()

	err = createTopicIfNotExists(brokers, topic)
	if err != nil {
		log.Fatalf("Failed to create topic: %v", err)
	}

	err = downloadCVEData()
	if err != nil {
		log.Fatalf("Error downloading CVE data: %v", err)
	}

	log.Println("Columns being indexed:")
	log.Println("1. Primary Key: (id, version)")
	log.Println("2. GIN index on the entire 'data' JSONB column")
	log.Println("3. GIN index on the 'cveMetadata' object within the 'data' column")

	// Process CVE JSON files and publish to Kafka
	processAndPublishCVEs(producer, topic)
}

func processAndPublishCVEs(producer sarama.SyncProducer, topic string) {

	processedCVEs := loadProcessedCVEs()

	// Open the cve_data.zip file
	zipFile, err := zip.OpenReader("cve_data.zip")
	if err != nil {
		log.Fatalf("Error opening cve_data.zip: %v", err)
	}
	defer zipFile.Close()

	totalFiles := len(zipFile.File)
	jsonFiles := 0
	publishedCVEs := 0
	log.Printf("Total files in zip: %d", totalFiles)

	// processedCVEs := make(map[string]bool)

	for _, file := range zipFile.File {
		if strings.HasSuffix(file.Name, ".json") && !strings.HasSuffix(file.Name, "delta.json") && !strings.HasSuffix(file.Name, "deltaLog.json") {
			jsonFiles++
			jsonFile, err := file.Open()
			if err != nil {
				log.Printf("Error opening JSON file: %s, %v", file.Name, err)
				continue
			}
			defer jsonFile.Close()

			data, err := ioutil.ReadAll(jsonFile)
			if err != nil {
				log.Printf("Error reading JSON file: %s, %v", file.Name, err)
				continue
			}

			var cveRecord CVERecord
			err = json.Unmarshal(data, &cveRecord)
			if err != nil {
				log.Printf("Error parsing CVE JSON data: %s, %v", file.Name, err)
				continue
			}

			// Check if this CVE has already been processed
			if processedCVEs[cveRecord.CveMetadata.CveID] {
				log.Printf("Skipping duplicate CVE: %s", cveRecord.CveMetadata.CveID)
				continue
			}

			// Publish to Kafka
			msg := &sarama.ProducerMessage{
				Topic: topic,
				Key:   sarama.StringEncoder(cveRecord.CveMetadata.CveID),
				Value: sarama.StringEncoder(data),
			}

			// Mark this CVE as processed
			processedCVEs[cveRecord.CveMetadata.CveID] = true

			partition, offset, err := producer.SendMessage(msg)
			if err != nil {
				log.Printf("Error publishing message to Kafka: %v", err)
			} else {
				publishedCVEs++
				log.Printf("Message published to partition %d at offset %d", partition, offset)
			}
		}
		saveProcessedCVEs(processedCVEs)
	}

	log.Printf("Total files in zip: %d", totalFiles)
	log.Printf("Total JSON files processed: %d", jsonFiles)
	log.Printf("Total unique CVEs published: %d", publishedCVEs)

}

func loadProcessedCVEs() map[string]bool {
	processedCVEs := make(map[string]bool)
	file, err := os.Open("processed_cves.txt")
	if err != nil {
		return processedCVEs
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		processedCVEs[scanner.Text()] = true
	}
	return processedCVEs
}

func saveProcessedCVEs(processedCVEs map[string]bool) {
	file, err := os.Create("processed_cves.txt")
	if err != nil {
		log.Printf("Error creating processed_cves.txt: %v", err)
		return
	}
	defer file.Close()

	writer := bufio.NewWriter(file)
	for cve := range processedCVEs {
		writer.WriteString(cve + "\n")
	}
	writer.Flush()
}

func createTopicIfNotExists(brokers []string, topic string) error {
	config := sarama.NewConfig()
	config.Version = sarama.V2_8_0_0

	admin, err := sarama.NewClusterAdmin(brokers, config)
	if err != nil {
		return fmt.Errorf("error creating cluster admin: %v", err)
	}
	defer admin.Close()

	topics, err := admin.ListTopics()
	if err != nil {
		return fmt.Errorf("error listing topics: %v", err)
	}

	if _, exists := topics[topic]; !exists {
		err = admin.CreateTopic(topic, &sarama.TopicDetail{
			NumPartitions:     1,
			ReplicationFactor: 1,
		}, false)
		if err != nil {
			return fmt.Errorf("error creating topic: %v", err)
		}
	}

	return nil
}

func downloadCVEData() error {
	url := "https://github.com/CVEProject/cvelistV5/archive/refs/heads/main.zip"
	zipFileName := "cve_data.zip"

	// Create the file
	out, err := os.Create(zipFileName)
	if err != nil {
		return err
	}
	defer out.Close()

	// Download the ZIP file
	resp, err := http.Get(url)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// Write the ZIP file to disk
	_, err = io.Copy(out, resp.Body)
	if err != nil {
		return err
	}

	return nil
}
