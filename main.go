package main

import (
	"archive/zip"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/IBM/sarama"
)

type CVERecord struct {
	Containers struct {
		CNA struct {
			Affected []struct {
				Product  string `json:"product"`
				Vendor   string `json:"vendor"`
				Versions []struct {
					Status  string `json:"status"`
					Version string `json:"version"`
				} `json:"versions"`
			} `json:"affected"`
			Descriptions []struct {
				Lang  string `json:"lang"`
				Value string `json:"value"`
			} `json:"descriptions"`
			ProblemTypes []struct {
				Descriptions []struct {
					Description string `json:"description"`
					Lang        string `json:"lang"`
					Type        string `json:"type"`
				} `json:"descriptions"`
			} `json:"problemTypes"`
			ProviderMetadata struct {
				DateUpdated string `json:"dateUpdated"`
				OrgID       string `json:"orgId"`
				ShortName   string `json:"shortName"`
			} `json:"providerMetadata"`
			References []struct {
				Name string   `json:"name"`
				Tags []string `json:"tags"`
				URL  string   `json:"url"`
			} `json:"references"`
			XLegacyV4Record struct {
				CVEDataMeta struct {
					Assigner string `json:"ASSIGNER"`
					ID       string `json:"ID"`
					State    string `json:"STATE"`
				} `json:"CVE_data_meta"`
				Affects struct {
					Vendor struct {
						VendorData []struct {
							Product struct {
								ProductData []struct {
									ProductName string `json:"product_name"`
									Version     struct {
										VersionData []struct {
											VersionValue string `json:"version_value"`
										} `json:"version_data"`
									} `json:"version"`
								} `json:"product_data"`
							} `json:"product"`
							VendorName string `json:"vendor_name"`
						} `json:"vendor_data"`
					} `json:"vendor"`
				} `json:"affects"`
				DataFormat  string `json:"data_format"`
				DataType    string `json:"data_type"`
				DataVersion string `json:"data_version"`
				Description struct {
					DescriptionData []struct {
						Lang  string `json:"lang"`
						Value string `json:"value"`
					} `json:"description_data"`
				} `json:"description"`
				ProblemType struct {
					ProblemTypeData []struct {
						Description []struct {
							Lang  string `json:"lang"`
							Value string `json:"value"`
						} `json:"description"`
					} `json:"problemtype_data"`
				} `json:"problemtype"`
				References struct {
					ReferenceData []struct {
						Name      string `json:"name"`
						Refsource string `json:"refsource"`
						URL       string `json:"url"`
					} `json:"reference_data"`
				} `json:"references"`
			} `json:"x_legacyV4Record"`
		} `json:"cna"`
	} `json:"containers"`
	CveMetadata struct {
		AssignerOrgID     string `json:"assignerOrgId"`
		AssignerShortName string `json:"assignerShortName"`
		CveID             string `json:"cveId"`
		DatePublished     string `json:"datePublished"`
		DateReserved      string `json:"dateReserved"`
		DateUpdated       string `json:"dateUpdated"`
		State             string `json:"state"`
	} `json:"cveMetadata"`
	DataType    string `json:"dataType"`
	DataVersion string `json:"dataVersion"`
}

const (
	batchSize = 1000 // Number of messages to send in each batch
	topic     = "cve"
)

func main() {

	err := downloadCVEData()
	if err != nil {
		log.Fatalf("Error downloading CVE data: %v", err)
	}

	fmt.Println("Successfully connected!")

	// Kafka producer configuration
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5

	// Get Kafka brokers from environment variable
	brokers := strings.Split(os.Getenv("KAFKA_BROKERS"), ",")
	if len(brokers) == 0 {
		log.Fatal("KAFKA_BROKERS environment variable is not set")
	}

	// Create Kafka producer
	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		log.Fatalf("Failed to create Kafka producer: %v", err)
	}
	defer producer.Close()

	// Open the cve_data.zip file
	zipFile, err := zip.OpenReader("cve_data.zip")
	if err != nil {
		log.Fatalf("Error opening cve_data.zip: %v", err)
	}
	defer zipFile.Close()

	var wg sync.WaitGroup
	recordChan := make(chan *CVERecord, batchSize)

	// Start the Kafka producer goroutine
	wg.Add(1)
	go func() {
		defer wg.Done()
		sendBatchToKafka(producer, recordChan)
	}()

	// Process CVE JSON files from the zip archive
	for _, file := range zipFile.File {
		if strings.HasSuffix(file.Name, ".json") && !strings.HasSuffix(file.Name, "delta.json") && !strings.HasSuffix(file.Name, "deltaLog.json") {
			jsonFile, err := file.Open()
			if err != nil {
				log.Printf("Error opening JSON file %s: %v", file.Name, err)
				continue
			}

			data, err := io.ReadAll(jsonFile)
			jsonFile.Close()
			if err != nil {
				log.Printf("Error reading JSON file %s: %v", file.Name, err)
				continue
			}

			var cveRecord CVERecord
			if err := json.Unmarshal(data, &cveRecord); err != nil {
				log.Printf("Error parsing CVE JSON data from file %s: %v", file.Name, err)
				continue
			}

			recordChan <- &cveRecord
		}
	}

	// Close the record channel to signal the end of processing
	close(recordChan)

	// Wait for the Kafka producer goroutine to finish
	wg.Wait()

	log.Println("CVE processing completed")
}

func downloadCVEData() error {
	url := "https://github.com/CVEProject/cvelistV5/archive/refs/heads/main.zip"
	zipFileName := "cve_data.zip"

	// Create the file
	out, err := os.Create(zipFileName)
	if err != nil {
		return err
	}
	defer out.Close()

	// Download the ZIP file
	resp, err := http.Get(url)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// Write the ZIP file to disk
	_, err = io.Copy(out, resp.Body)
	if err != nil {
		return err
	}

	return nil
}

func sendBatchToKafka(producer sarama.SyncProducer, recordChan <-chan *CVERecord) {
	batch := make([]*sarama.ProducerMessage, 0, batchSize)
	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case record, ok := <-recordChan:
			if !ok {
				// Channel closed, send remaining batch and return
				if len(batch) > 0 {
					sendBatch(producer, batch)
				}
				return
			}

			value, err := json.Marshal(record)
			if err != nil {
				log.Printf("Error marshaling CVE record: %v", err)
				continue
			}

			batch = append(batch, &sarama.ProducerMessage{
				Topic: topic,
				Value: sarama.ByteEncoder(value),
			})

			if len(batch) >= batchSize {
				sendBatch(producer, batch)
				batch = make([]*sarama.ProducerMessage, 0, batchSize)
			}

		case <-ticker.C:
			// Send any remaining messages every 5 seconds
			if len(batch) > 0 {
				sendBatch(producer, batch)
				batch = make([]*sarama.ProducerMessage, 0, batchSize)
			}
		}
	}
}

func sendBatch(producer sarama.SyncProducer, batch []*sarama.ProducerMessage) {
	err := producer.SendMessages(batch)
	if err != nil {
		log.Printf("Failed to send batch to Kafka: %v", err)
	} else {
		log.Printf("Successfully sent batch of %d messages to Kafka", len(batch))
	}
}
